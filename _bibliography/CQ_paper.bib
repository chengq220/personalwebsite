@misc{zhou_paraphrase_2024,
  abbr={arXiv},
  title={Paraphrase Identification with Deep Learning: A Review of Datasets and Methods},
  shorttitle={Paraphrase Identification with Deep Learning},
  author={Zhou, Chao and Qiu, Cheng and Liang, Lizhen and Acuna, Daniel E.},
  abstract={The rapid progress of Natural Language Processing (NLP) technologies has led to the widespread availability and effectiveness of text generation tools such as ChatGPT and Claude. While highly useful, these technologies also pose significant risks to the credibility of various media forms if they are employed for paraphrased plagiarism—one of the most subtle forms of content misuse in scientific literature and general text media. Although automated methods for paraphrase identification have been developed, detecting this type of plagiarism remains challenging due to the inconsistent nature of the datasets used to train these methods. In this article, we examine traditional and contemporary approaches to paraphrase identification, investigating how the under-representation of certain paraphrase types in popular datasets, including those used to train Large Language Models (LLMs), affects the ability to detect plagiarism. We introduce and validate a new refined typology for paraphrases (REPARAPHRASED, REfined PARAPHRASE typology definitions) to better understand the disparities in paraphrase type representation. Lastly, we propose new directions for future research and dataset development to enhance AI-based paraphrase detection.},
  language={en},
  year={2024},
  month={Sept},
  url={http://arxiv.org/abs/2212.06933},
  doi={10.48550/arXiv.2212.06933},
  altmetric={3271},
  annotation={* Highlights progress in paraphrase identification methods<br>* Discusses dataset inconsistencies for Large Language Models},
  additional_info={* See full text on [arXiv](http://arxiv.org/abs/2212.06933)},
  keywords={Natural Language Processing, Paraphrase Detection, Artificial Intelligence},
  pdf={paraphrase.pdf},
  selected={false}
}

@misc{qiu_leaving_2024,
  abbr={arXiv},
  title={Leaving Some Facial Features Behind},
  author={Qiu, Cheng},
  abstract={Facial expressions are crucial to human communication, offering insights into emotional states. This study examines how specific facial features influence emotion classification, using facial perturbations on the Fer2013 dataset. As expected, models trained on data with the removal of some important facial features experienced up to an 85\% accuracy drop when compared to baseline for emotions like happy and surprise. Surprisingly, for the emotion disgust, there seem to be slight improvement in accuracy for the classifier after masks have been applied. Building on this observation, we proposed a training scheme to mask out facial features during training, motivating our Perturb Scheme. This scheme, with three phases—attention-based classification, pixel clustering, and feature-focused training—demonstrates improvements in classification accuracy. The experimental results obtained suggest there are some benefits to removing individual facial features in emotion recognition tasks.},
  language={en},
  year={2024},
  month={Oct},
  url={http://arxiv.org/abs/2411.00824},
  doi={10.48550/arXiv.2411.00824},
  altmetric={1438},
  annotation={* Introduces "Perturb Scheme" for improved emotion classification<br>* Suggests benefits of masking specific facial features in training},
  additional_info={* More information can be found on [arXiv](http://arxiv.org/abs/2411.00824)},
  keywords={Computer Vision, Emotion Recognition, Artificial Intelligence},
  pdf={facial.pdf},
  selected={false}
}
